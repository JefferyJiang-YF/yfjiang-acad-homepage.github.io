---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


Welcome to my academic portfolio. I am a dedicated researcher with a deep commitment to advancing the field of medical imaging and computer vision. My work primarily revolves around the development and refinement of multi-modal models, which integrate various forms of data to enhance learning and predictive accuracy.

Currently, I am engaged as a Part-Time Research Assistant (PT RA) at HKMU, where my research focuses on Natural Language Processing (NLP) and Vision-Language Models (VLM). I am particularly fascinated by the potential of foundation models in transforming information retrieval systems, making them more intuitive and efficient.

Through my research, I aim to bridge the gap between theoretical computer science and practical, impactful applications in healthcare and digital information systems. If you have any inquiries or need consultation, please feel free to contact me at [your email].

Join me as I explore the cutting-edge of technology and medicine, striving to innovate solutions that improve both diagnostics and accessibility to information.

# üî• News
- *2024.03*: &nbsp;üéâüéâ I'm joining PolyU as a incoming Ph.D. student. Another new journey is coming! 
- *2024.06-*: &nbsp;üéâüéâ I am currently working as a Research Assistant (RA) at HKMU, focusing on Natural Language Processing (NLP) research. 

# üìù Publications 

<div class='paper-box'>
<div class='paper-box-image'>
<div>
<div class="badge">ICSP 2022</div>
<img src='images/ICSP22.png' alt="sym" width="100%">
</div>
</div>
<div class='paper-box-text' markdown="1">

[COTS recognition and detection based on Improved YOLO v5 model](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778430)

**Yufeng Jiang**

[**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=0_gONvUAAAAJ&citation_for_view=0_gONvUAAAAJ:u5HHmVD_uO8C) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- **Research Focus**: Utilizing YOLOv5 and WBF models to accurately detect and monitor the distribution of crown-of-thorns starfish (COTS), crucial for the protection of the Great Barrier Reef.
- **Key Achievements**:
  - Developed a high-precision detection model verified on KAGGLE, demonstrating significant improvement over traditional methods like Faster R-CNN.
  - Provided actionable insights for sustainable ecological management and protection strategies of the reef ecosystem.
</div>
</div>

<div class='paper-box'>
<div class='paper-box-image'>
<div>
<div class="badge">MICCAI 2024</div>
<img src='images/24.png' alt="sym" width="100%">
</div>
</div>
<div class='paper-box-text' markdown="1">

[M<sup>4</sup>oE: A Foundation Model for Medical Multimodal Image Segmentation with Mixture of Experts](https://arxiv.org/pdf/2405.09446)

**Yufeng Jiang**, Yiqing Shen

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=0_gONvUAAAAJ&citation_for_view=0_gONvUAAAAJ:qjMakFHDy7sC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- The Medical Multimodal Mixture of Experts (M4oE) framework, based on SwinUNet architecture, addresses the challenge of multimodal medical image segmentation by employing modality-specific experts and a dynamic gating network for enhanced scalability and interpretability. M4oE not only achieves superior performance across multiple datasets but also significantly reduces computational overhead, making it highly efficient for handling diverse medical imaging data. The full implementation and experiments are detailed on the project's GitHub repository, available at [M4oE GitHub](https://github.com/JefferyJiang-YF/M4oE).
</div>
</div>

- [Jiang, Yufeng., Li, F., Li, Z., Liu, Z., & Wang, Z. Enhancing Continuous Sign Language Recognition with Self-Attention and MediaPipe Holistic](https://ieeexplore.ieee.org/abstract/document/10273118), In Proceedings of the 8th International Conference on Instrumentation, Control and Automation, **ICA 2023**

- [Wang, Zijian, Liu, Ziwei, Li, Zongxi, Jiang, Yufeng, and Li, Fengheng. ‚ÄúAmerican Sign Language Alphabet Recognition with YOLOv5 Enhanced by MediaPipe Hands.‚Äù](https://ieeexplore.ieee.org/abstract/document/10273099), In Proceedings of the 8th International Conference on Instrumentation, Control and Automation, **ICA 2023**

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üéñ Honors and Awards
- *2020-2023* Dean‚Äôs List (6 times in my bachelor's degree)
- *2022-2023* Outstanding Student Award (Top Student, 2 times in my bachelor's degree)
- *2022-2023* Outstanding Student Scholarship (1 time in my bachelor's degree)
- *2023.12* Distinction Scholarship (in my master's degree)
- *2024.06* Distinction Scholarship (in my master's degree)

# üìñ Educations

- *2024.09 - (now)*, Ph.D. in Computer Science, The Hong Kong Polytechnic University, Hong Kong.
- *2023.09 - 2024.06*, M.S. in Computer Science, Hong Kong Baptist University, Hong Kong (cGPA 3.79/4, taught in Eng).
- *2019.09 - 2023.06*, B.S. in Computer Science, Hong Kong Metropolitan University, Hong Kong (cGPA 3.54/4, taught in English).


# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2024.06 - (now)*, Research Assistant, Hong Kong Metropolitan University.
- *2022.01 - 2022.02*, Remote Internship, Nanyang Technological University.
  - **Python for Data Analytics**
  ‚Äì Data Analysis using Python: Utilized Numpy, Pandas, Matplotlib, and Seaborn for data analysis and visualization.
  ‚Äì Machine Learning Principles: Mastered unsupervised learning and supervised learning principles. ‚Äì Scikit-learn: Proficient in using the scikit-learn machine learning library.
- *2022.01 - 2022.02*, Remote Internship, Imperial College, London.
  - **Innovating the Future with Robotics, IoT, and AI**
  ‚Äì Machine Learning with Python: Mastered using k-NN and k-means for image recognition processing, as well as decision trees for accurate image recognition.
  ‚Äì Understanding Robotics and Artificial Intelligence: Gained insights into the challenges and opportunities in modern robotics and artificial intelligence development.